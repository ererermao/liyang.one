<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[spark2.x中一个NoSuchMethodError错误]]></title>
    <url>%2F2017%2F11%2F06%2F20171106-spark2-x%E4%B8%AD%E4%B8%80%E4%B8%AANoSuchMethodError%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[使用spark_shuffle的时候遇到的.之前编译1.6的时候没有问题. ¶1. 背景: cdh5.11.2 版本的hadoop yarn hbase spark 版本为apache 2.0.2 自己编译spark on cdh com.fasterxml.jackson.core 版本为:2.6.5 ¶2. 操作: 按照 http://blog.csdn.net/windyqcf/article/details/70140404 这个教程,使用yarn动态资源分配 其中使用到的这个 org.apache.spark.network.yarn.YarnShuffleService 来源 spark-2.0.2-yarn-shuffle.jar ¶3. 问题: 在重启yarn的时候报错:java.lang.NoSuchMethodError: org.spark_project.com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z ¶4. 自我分析: NoSuchMethodError 一般就2种情况:1. 没有这个类这个方法 2. 有多个类名冲突 jar -tvf spark-2.0.2-yarn-shuffle.jar | grep “org.spark_project.com.fasterxml.jackson.core.JsonFactory” : 是有这方法的 查看编译的pom.xml 发现用的 jackson.core2.6.5 ,通过源码 发现有这个类:https://github.com/FasterXML/jackson-core/blob/2.6/src/main/java/com/fasterxml/jackson/core/JsonFactory.java grep -rni “org.spark_project.com.fasterxml.jackson.core.JsonFactory.requiresPropertyOrdering()Z” /usr/lib/ (hadoop 所有相关lib全在这个目录下) : 没有类名冲突 ¶5. 尝试解决 网上发现有可能是 jackson 版本问题,修改为2.8.5 , 还是这个错 ¶6. 求解决]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>NoSuchMethodError</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos7编译mysql5.7.18(camke)]]></title>
    <url>%2F2017%2F10%2F20%2F20171013-centos7%E7%BC%96%E8%AF%91mysql5-7-18-camke%2F</url>
    <content type="text"><![CDATA[最近有需求安装高版本的mysql做测试，学习并记录一下camke的安装方式 ¶1、前提准备 ¶1.1 需要用到的工具包 1sudo um -y install gcc gcc-c++ ncurses ncurses-devel cmake bison ¶1.2 下载源码（建议去官方下载） 1234## mysql源代码 如果下载慢，可以用代理wget https://dev.mysql.com/get/Downloads/MySQL-5.7/mysql-5.7.18.tar.gz## boost 库，5.7.5开始需要wget http://downloads.sourceforge.net/project/boost/boost/1.59.0/boost_1_59_0.tar.gz ¶1.3 创建mysql 用户和目录 123456## 创建用户 禁止登录sudo groupadd -r mysqlsudo useradd -r -M -g mysql -s /sbin/nologin mysql ## 创建目录，自己定义路径sudo mkdir /opt/mysql ¶2、编译 安装 ¶2.1 预编译 12345678910111213141516171819202122232425# 解压tar -zxvf boost_1_59_0.tar.gz -C ../build tar -zxvf mysql-5.7.18.tar.gz -C ../build/cd ../build/mysql-5.7.18# 预编译 文末有配置说明cmake -DCMAKE_INSTALL_PREFIX=/opt/mysql \-DMYSQL_DATADIR=/opt/mysql/data \-DMYSQL_UNIX_ADDR=/opt/mysql/mysql.sock \-DWITH_BOOST=../boost_1_59_0 \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DWITH_FEDERATED_STORAGE_ENGINE=1 \-DWITH_BLACKHOLE_STORAGE_ENGINE=1 \-DWITH_MYISAM_STORAGE_ENGINE=1 \-DENABLED_LOCAL_INFILE=1 \-DENABLE_DTRACE=0 \-DDEFAULT_CHARSET=utf8mb4 \-DDEFAULT_COLLATION=utf8mb4_general_ci \-DWITH_EMBEDDED_SERVER=1# 编译并安装make make install make clean ¶3、配置 ¶3.1 设置启动脚本以及开启启动 123456#拷贝可执行文件到指定的目录下，并修改名字为mysqldsudo cp /opt/mysql/support-files/mysql.server /etc/init.d/mysqld#授予可执行的权限sudo chmod +x /etc/init.d/mysqld#设置为开机启动 sudo systemctl enable mysqld ¶3.2 权限 1sudo chown -R mysql:mysql /opt/mysql ¶3.3 环境变量 123## sudo vim /etc/profile.d/mysql.sh 并加入下面2句话export MYSQL_HOME=/opt/msyqlexport PATH=$PATH:MYSQL_HOME/bin ¶4、初始化并启动 ¶4.1 初始化mysql 1234mysqld –initialize --user=mysql --datadir=/opt/mysql/data/### mysql5.7会生成一个初始化密码在用户的～/.mysql_secret ¶4.2 启动，并修改root密码 12345678# 启动systemctl start mysqld# 登录mysql -uroot -p***** #**** 在用户的 ～/.mysql_secret# 修改密码ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED BY &apos;********&apos; ¶后续 ¶4、配置解释 12345678910### 配置大致解释配置解释：-DCMAKE_INSTALL_PREFIX=/usr/local/mysql //设置安装目录-DMYSQL_DATADIR=/home/mysql/data //设置数据库存放目录 -DMYSQL_UNIX_ADDR=/usr/local/mysql/mysql.sock //设置UNIX socket目录-DDEFAULT_CHARSET=utf8mb4 //设置默认字符集-DDEFAULT_COLLATION=utf8mb4_general_ci //设置默认校对规则-DWITH_INNOBASE_STORAGE_ENGINE=1 //添加InnoDB引擎支持-DSYSCONFDIR=/etc //设置my.cnf配置文件的所在目录，默认为安装目录 ¶5、问题集 ¶5.1 Too many arguments (first extra is ‘start’). 删除profile的配置， ¶5.2 ExecStart=/etc/rc.d/init.d/mysqld start (code=exited, status=1/FAILURE) 直接用命令执行，可以看到更详细的日志 ¶5.3 mysqld_safe error: log-error set to ‘/var/log/mariadb/mariadb.log’, however file don’t exists. Create writable for user ‘mysql’. touch /var/log/mariadb/mariadb.log &amp;&amp; chmod 777 /var/log/mariadb/mariadb.log ¶5.4 os_file_get_status() failed on ‘./ibdata1’. Can’t determine file permissions or InnoDB: ./ib_logfile0 can’t be opened in read-write mode 目录的权限问题，就先简单粗暴解决吧，chwon -R 777 /opt/mysql]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>centos</tag>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark2.x编译]]></title>
    <url>%2F2017%2F09%2F29%2F20170929-spark2-x%E7%BC%96%E8%AF%91%2F</url>
    <content type="text"><![CDATA[编译随记 ¶1、基础环境（忽略） maven scala2.11+ ¶2、下载源码 先下载源码，可以去 http://archive.apache.org/dist/spark http://archive.apache.org/dist/spark/ ¶3、添加源 在根目录的pom.xml里面添加下面这一句 12345&lt;repository&gt; &lt;id&gt;cloudera&lt;/id&gt; &lt;name&gt;cloudera Repository&lt;/name&gt; &lt;url&gt;https://repository.cloudera.com/artifactory/cloudera-repos&lt;/url&gt;&lt;/repository&gt; ¶4、编译 12345678910## 调整jvm大小export MAVEN_OPTS="-Xmx2g -XX:ReservedCodeCacheSize=512m"## 官方建议用make-distribution.sh 编译./dev/make-distribution.sh --name custom-spark --tgz -Pyarn -Phadoop-2.6 -Dhadoop.version=2.6.0-CDH5.11.2 -Phive -Phive-thriftserver ./dev/make-distribution.sh --name custom-spark --tgz -Dhadoop.version=2.6.0-CDH5.11.2 -Dhbase.version=1.2.0-CDH5.11.2 -Phadoop-2.6 -Phbase-1.2 -Pyarn -Phive -Phive-thriftserver ## maven 编译命令mvn -e -Phadoop-2.6 -Dhadoop.version=2.6.0-CDH5.11.2 -Phive -Phive-thriftserver -Pyarn -DskipTests clean package ¶5、可能遇到的问题 ¶5.1 Failed to execute goal org.codehaus.mojo:exec-maven-plugin:1.4.0:exec (sparkr-pkg) on project spark-core_2.10: Command execution failed. Process exited with an error: 127 (Exit value: 127) -&gt; [Help 1] 解决： 在编译命令去掉 -Pyarnr 这个参数]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>cdh</tag>
        <tag>spark</tag>
        <tag>spark2.x</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[未归类的问题集]]></title>
    <url>%2F2017%2F08%2F10%2F20170810-%E6%9C%AA%E5%BD%92%E7%B1%BB%E7%9A%84%E9%97%AE%E9%A2%98%E9%9B%86%2F</url>
    <content type="text"><![CDATA[未归类的一些问题集 ¶1、ss.panel/vendor/autoload.php: No such file or directory 需要执行：php composer.phar install ¶2、php版本 大于5.6 ¶3、php -n xcat createAdmin Fatal error: Interface ‘JsonSerializable’ not found in /home/ss/ss.panel/vendor/sendgrid/sendgrid/lib/helpers/mail/Mail.php on line 16 去掉 -n ¶20170607 ¶4、error: not found: value hiveCtx import org.apache.spark.sql.hive.HiveContext val hiveCtx = new HiveContext(sc) ¶5、http://liuyq1991.iteye.com/blog/2270678 Error in configuring object ¶6、 问题4：java.sql.SQLException: Failed to start database ‘metastore_db’ with class loader org.apache.spark.sql.hive.client.IsolatedClientLoader$$anon$1@5a0039e7, see the next exception for details 只是要注意一点：在运行程序之前，千万不要运行脚本sbin/start-thriftserver.sh,否则自己写的程序是无法运行的 情形一：已经有一个hive连接在访问Derby创建的metastore_db文件夹，由于Derby数据库自身的缺点–仅支持一个链接对其进行访问，所以这时，如果再有一个终端调用hive，就有第二个链接访问Derby数据库了，就会抛出这个异常。 解决方法很简单。用mysql作为元数据仓库，mysql支持多链接访问，这个问题就不存在了。 情形二：突然离线，易造成hive没能来得及删除自动创建的metastore_db文件夹(~home/bin/metastore_db),这时再次用hive命令进入，则会产生如下报错。 解决这一问题很简单。将metastore_db文件夹改名或者干脆删除，然后重新运行hive命令启动即可。 spark_home 将metastore_db文件夹改名或者干脆删除 ¶7、spark 动态资源分配 http://lxw1234.com/archives/2015/12/593.htm ¶9、unread block data 17/06/28 11:14:35 INFO spark.SparkContext: Running Spark version 1.6.0 17/06/28 11:14:35 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable 17/06/28 11:14:36 WARN spark.SparkConf: SPARK_CLASSPATH was detected (set to ‘:/usr/lib/spark-1.6.0-bin-hadoop2.6/lib/hbase/*::/usr/lib/spark-1.6.0-bin-hadoop2.6/conf’). This is deprecated in Spark 1.0+. Please instead use: ./spark-submit with --driver-class-path to augment the driver classpath spark.executor.extraClassPath to augment the executor classpath 17/06/28 11:14:36 WARN spark.SparkConf: Setting ‘spark.executor.extraClassPath’ to ‘:/usr/lib/spark-1.6.0-bin-hadoop2.6/lib/hbase/::/usr/lib/spark-1.6.0-bin-hadoop2.6/conf’ as a work-around. 17/06/28 11:14:36 WARN spark.SparkConf: Setting ‘spark.driver.extraClassPath’ to ':/usr/lib/spark-1.6.0-bin-hadoop2.6/lib/hbase/::/usr/lib/spark-1.6.0-bin-hadoop2.6/conf’ as a work-around. 解决办法：–jars ¶10、had a not serializable result 1234567891011121314151617181920212223242526272829303132333435363738394017/06/28 14:36:12 ERROR scheduler.TaskSetManager: Task 0.0 in stage 1.0 (TID 1) had a not serializable result: org.apache.hadoop.hbase.io.ImmutableBytesWritableSerialization stack: - object not serializable (class: org.apache.hadoop.hbase.io.ImmutableBytesWritable, value: 72 6f 77 33) - field (class: scala.Tuple2, name: _1, type: class java.lang.Object) - object (class scala.Tuple2, (72 6f 77 33,keyvalues=&#123;row1/info:age/1498564460423/Put/vlen=2/seqid=0, row1/info:mail/1498564470928/Put/vlen=15/seqid=0, row1/info:name/1498564445991/Put/vlen=8/seqid=0&#125;)) - element of array (index: 0) - array (class [Lscala.Tuple2;, size 3); not retryingException in thread "main" org.apache.spark.SparkException: Job aborted due to stage failure: Task 0.0 in stage 1.0 (TID 1) had a not serializable result: org.apache.hadoop.hbase.io.ImmutableBytesWritableSerialization stack: - object not serializable (class: org.apache.hadoop.hbase.io.ImmutableBytesWritable, value: 72 6f 77 33) - field (class: scala.Tuple2, name: _1, type: class java.lang.Object) - object (class scala.Tuple2, (72 6f 77 33,keyvalues=&#123;row1/info:age/1498564460423/Put/vlen=2/seqid=0, row1/info:mail/1498564470928/Put/vlen=15/seqid=0, row1/info:name/1498564445991/Put/vlen=8/seqid=0&#125;)) - element of array (index: 0) - array (class [Lscala.Tuple2;, size 3) at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1431) at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1419) at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1418) at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59) at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:47) at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1418) at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.a在使用Spark操作Hbase的时候，其返回的数据类型是RDD[ImmutableBytesWritable,Result]，我们可能会对这个结果进行其他的操作，比如join等，但是因为org.apache.hadoop.hbase.io.ImmutableBytesWritable 和 org.apache.hadoop.hbase.client.Result 并没有实现 java.io.Serializable 接口，程序在运行的过程中可能发生以下的异常 stuRDD.foreach(&#123; case (_,result) =&gt; val key = Bytes.toString(result.getRow) val name = Bytes.toString(result.getValue("info".getBytes,"name".getBytes)) val gender = Bytes.toString(result.getValue("info".getBytes,"mail".getBytes)) val age = Bytes.toString(result.getValue("info".getBytes,"age".getBytes)) println("Row key:"+key+" Name:"+name+" Gender:"+gender+" Age:"+age) &#125;)val sc = new SparkContext(new SparkConf().set("spark.serializer", "org.apache.spark.serializer.KryoSerializer"))val stuRDD = sc.newAPIHadoopRDD(conf, classOf[TableInputFormat],classOf[ImmutableBytesWritable],classOf[Result]) ¶11、Could not load native gpl library no gplcompression in java.library.path 测试是没有问题的hdfs dfs -text /home/bi/shaoyu/11.txt.lzo ¶12、 json scala json4s http://kubicode.me/2015/05/24/Scala/Study-And-User-JSON4S/ lift-json https://gxnotes.com/article/72792.html ¶13 、 12Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: net/liftweb/json/package$Exception in thread &quot;main&quot; java.lang.NoClassDefFoundError: org/json4s/native/JsonMethods$ 估计是版本问题 升级jdk版本 和scala版本 jdk1.8 scala 2.11.11 jar 3.0 官方文档： 1Spark runs on Java 7+, Python 2.6+ and R 3.1+. For the Scala API, Spark 1.6.0 uses Scala 2.10. You will need to use a compatible Scala version (2.10.x). 最终答案： 到目前为止，都很happy，因为都能顺利通过，因为你依赖的spark库，在spark master和worker上面都有。但是如果依赖mysql的jdbc这些第三方库, 只使用sbt的 package 命令打包，是不会把这些第三方库打包进去的。 ¶14、 Modules were resolved with conflicting cross-version suffixes in sbt 版本配置文件，版本冲突 ¶15、 ./sbt/sbt assembly 编译spark报错 需要安装git java 需要配置同名的过滤条件 ¶16、json 单引号 双引号 标准为双引号 可以通过第三方工具来使用 ¶18、Not a host:port pair: PBUF hive 整合hbase的时候，hbase包的版本不一致 ¶17、Connection reset by peer 在执行hbase put的过程中报出的 ¶18 、 http://www.haowt.info/archives/205.html ¶19 kettle 加载不了资源库， 在设置里面关闭了一些加载，就好了。至于什么忘记了下]]></content>
      <categories>
        <category>未归类</category>
      </categories>
      <tags>
        <tag>未归类</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[archlinux的优化]]></title>
    <url>%2F2017%2F07%2F13%2F20170713-archlinux%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[¶1、pacman/yaorut 1234567891011121314151617181920212223#-n 6:将生成6个最接近的源，运行rankmirrors -h可查看所有可用选项。rankmirrors -n 6 mirrorlist.backup &gt; mirrorlist#/etc/pacman.conf彩色输出：取消#Color中的#号。升级前对比版本：取消#VerbosePkgLists#号。#社区镜像 必须放在最后添加社区仓库：[archlinuxcn] Server = https://mirrors.ustc.edu.cn/archlinuxcn/$arch#multilib 可以运行 编译32位 后面用wine需要添加multilib仓库：[archlinuxcn] Server = https://mirrors.ustc.edu.cn/archlinuxcn/$archpacman -R $(paclist multilib | cut -f1 -d' ') # 恢复纯64位系统#archlinuxcn-keyring 包以导入 GPG key。pacman -S archlinuxcn-keyring#aur工具yaourtpacman -S yaourt#aur 评论工具pacman -S aurvote #安装该工具aurvote --configure #配置用户名密码 ¶2、系统 1、 解决办法：关掉系统蜂鸣声 移出蜂鸣系统模块：rmmod pcspkr 当你怀念它的时候：modprobe pcspkr 2、tweak 优化工具 扩展 开启 window list ¶3、工具 1、终端 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657guake #下拉式终端tumx # 分页 分窗口oh-my-zsh # 替代bashfasd # 快速跳转目录#配置oh-my-zshwget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | shchsh -s /usr/local/bin/zshhttp://yijiebuyi.com/blog/b9b5e1ebb719f22475c38c4819ab8151.htmlalsa-utils #声音管理screenfetch #打印版本firefox #火狐浏览器firefox-i18n-zh-cn chromium flashplugin #火狐中文http://ftp.mozilla.org/pub/firefox/releases/54.0.1/linux-x86_64/xpi/zh-CN.xpi火狐插件：vimfx #vim 操作浏览器lastpass #密码管理eversync #标签同步tor #洋葱浏览器 匿名聊天mpv #视频播放器wine #可运行windows的底层工具fcitx-im #输入法fcitx-googlepinyin #谷歌输入法fcitx-configtool #图形化管理fcitxwget #下载axel #多线程下载openssh # ssh工具netease-cloud-music #网易云音乐iotop #io 监控iftop #网络监控telegram-desktop #聊天工具foxitreader #福昕PDF阅读器FBReader # mobi 阅读器jq # 检验jsonpeek #gif 录制https://www.zhihu.com/question/59227720# 基本命令替换htop &lt;- top # 内存 cpu等进程信息advcp &lt;- cp mv # cp and mv proxychains-ng # 终端代理 ftp https http ping 不行you-get # 下载网站的视频]]></content>
      <categories>
        <category>archlinux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>arch</tag>
        <tag>archlinux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[archlinux的安装]]></title>
    <url>%2F2017%2F07%2F11%2F20170711-archlinux%E7%9A%84%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[一直以来都是笔记本用的archlinux,工作用的windows。最近公司要求在电脑上各种东西管控，一会企业360，一会windows的域。只有就一直打算切换arch但是怕各种不兼容，现在试试。 本文作为个人记录，不作为安装教程。所以到时候会缺少很多图片内容 ¶一、 准备工作 1、制作u盘 1234567891011121314 ## 注意这里of指向整个硬盘不带数字的 dd if=xxx.iso of=dev/sdb ``` #### 二、 配置工作 1、分区方案： ```shell /boot 500m # 需要单独分区 /swap 8g # 一般为内存 1倍 /var 20g #2 /tmp 10G / 50G /home all 2、操作命令 12345678910111213141516171819201、 分区fdisk /dev/sda n p 1 default +200M #新建分区t 2 8e #新建8e的逻辑卷分区reboot #重启2、创建物理卷 卷组 逻辑卷pvcreate /dev/sdb2 #创建物理卷vgcreate vgname /dev/sdb2 /dev/sdc1 # 创建卷组lvcreate -L 5G vgname -n lvname #创建逻辑卷lvcreate -l 100%FREE vgname -n lvname #剩余所有空间分配到该逻辑卷3、格式化所有分区，不包括swapmkfs.ext4 /dev/sda1 # 格式化4、swap 分区mkswap /dev/xxx #格式化swapswapon /dev/xxx # 启用swapon -s #查看/dev/sda2 none swap defaults 0 0 #加入fstab 自启动 3、挂载 123mount /dev/vg/lv_root /mnt # /mount /dev/vg/lv_home /mnt/home #/homemount /dev/vg/lv_boot /mnt/boot #/boot 4、查看网络 ping www.baidu.com 如果不通：systemctl stop dhcpcd 5、修改镜像 /etc/pacman.d/mirrorlist 选择一个国内的源 ¶三、安装工作 1、安装 1pacstrap -i /mnt base base-devel # 安装 devel 可以使用aur 2、常规配置 123456789101112131415161718192021222324252627281、生成fstabgenfstab -U /mnt &gt;&gt; /mnt/etc/fstab # U:ID L:卷标2、进入系统arch-chroot /mnt3、时间ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime4、文本/etc/locale.gen # 取消注释 us zh utf-8的locale-gen #生效5、密码passwd root6、hostname echo name &gt;&gt; /etc/hostname7、引导grub # 注意一定要挂载bootpacman -S grubgrub-install --target=i386-pc /dev/sdxgrub-mkconfig -o /boot/grub/grub.cfg8、重启exitumount -R /mntreboot ¶四、后期优化工作 1、网络 有线：systemctl ensable dhcpcd 2、ip 查看：ip addr show 3、建立日常使用账户 12useradd -m namepasswd name 4、sudo权限 修改/etc/sudoers name ALL=(ALL) NOPASSWD: ALL 5、显卡驱动 12345678lspci | grep VGA # 查看pacman -S xf86-video-vesa #通用显卡pacman -S xf86-video-intel #intel集成显卡pacman -S xf86-video-ati #amd/atipacman -S nvidia #nvidia# 老式nvidia显卡（一般2010以前）如GeForce 8000/9000、ION、FGeForce 6000/7000等等pacman -S nvidia-304xx 6、图形化界面 1234pacman -S plasma #plasma(kde5)pacman -S gnome #gnome3pacman -S xfce4 #xfce4pacman -S lxde #lxde 7、字体 pacman -S wqy-microhei 更多点击这 ¶五、错误集 1、warning failed to connect to lvmetad，falling back to device scanning 编辑/etc/lvm/lvm.conf这个文件，找到use_lvmetad = 1将1修改为0，保存，重新配置grub。 2、无法进行引导 由于安装时，没有挂载boot。在boot目录没有该有的*.img文件。 3、error: device ‘dev/maper/vg-lv_root’ skipping fsck mount you must specify the filesystem type 没有激活lvm2钩子。修改/etc/mkinitcpio.conf中：HOOKS=“base udev autodetect modconf block lvm2 filesystems keyboard fsck” （添加 lvm2） 4、vim : Error reading input, exiting 很奇怪的，莫名的语言配置就没了。执行以下： echo LANG=en_US.UTF-8 &gt; /etc/locale.conf]]></content>
      <categories>
        <category>archlinux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>arch</tag>
        <tag>archlinux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.so文件缺失或大小为0]]></title>
    <url>%2F2017%2F05%2F08%2F20170508-so%E6%96%87%E4%BB%B6%E7%BC%BA%E5%A4%B1%E6%88%96%E5%A4%A7%E5%B0%8F%E4%B8%BA0%2F</url>
    <content type="text"><![CDATA[¶1、科普： Linux中的.so文件类似于Windows中的DLL，是动态链接库，也有人译作共享库（因so的全称为Shared Object）。当多个程序使用同一个动态链接库时，既能节约可执行文件的大小，也能减少运行时的内存占用。 ¶2、问题： 常见的错误日志： lib*.so.* :file too short lib*.so.* is empty ,not checked ¶3、解决 #查询出目前有问题的.so文件 ldconfig #搜索该.so的所属软件包(如果没有搜索到直接谷歌：libasound) pacman -Qo /usr/lib/libasound.so #重装 pacman -S --force alas-lib]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客迁移记录]]></title>
    <url>%2F2017%2F05%2F04%2F20170504-%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[¶1、前言 博客已经一年多,生成网页的hexo一直放在工作的windows上面的.现在有了一台nas，将生成页面的hexo放在nas上面。在此记录一下一些安装步骤，方便迁移。 ¶2、环境搭建 我的nas是centos，所以一下为centos的命令 ¶2.1 添加yum源 yum install epel-release ¶2.2 安装基础环境 yum install nodejs npm ¶2.3 配置npm国内镜像 npm config set registry http://registry.npm.taobao.org ¶2.4 安装hexo npm install -g hexo-cli ¶2.5 初始化hexo mkdir /opt/hexo &amp;&amp; cd /opt/hexo &amp;&amp; hexo init ¶3、迁移 ¶3.1 配置文件 根目录下的_config.yml等等 ¶3.2 主题 themes\hexo 复制整个文件夹 ¶3.3 资源 根目录source整个文件夹 ¶3.4 一些功能 ¶3.4.1 压缩 拷贝压缩的配置文件gulpfile.js 安装插件： npm install --global gulp npm install gulp-clean gulp-htmlclean gulp-htmlmin gulp-load-plugins gulp-minify-css gulp-minify-html gulp-rename gulp-shell gulp-uglify gulp-imagemin ¶3.4.2 sitemap网站地图 文件在source文件夹里面，所以不用再拷贝了 安装插件： npm install hexo-generator-sitemap hexo-generator-baidu-sitemap --save ¶3.4.3 搜索 配置在_config.yml npm install hexo-generator-searchdb]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[升级python2.7后easy_install报错：No module named pkg_resources]]></title>
    <url>%2F2017%2F04%2F27%2F20170427-%E5%8D%87%E7%BA%A7python2-7%E5%90%8Eeasy-install%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[centos6升级后python2.7后执行easy_install --h会有以下错误： 12345$ easy_install --hTraceback (most recent call last): File &quot;/usr/bin/easy_install&quot;, line 5, in &lt;module&gt; from pkg_resources import load_entry_pointImportError: No module named pkg_resources 解决办法如下： 1234$wget http://pypi.python.org/packages/source/s/setuptools/setuptools-0.6c5.tar.gz$tar zxvf setuptools-0.6c5.tar.gz$cd setuptools-0.6c5$python setup.py install]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark error：not found：value StorageLevel]]></title>
    <url>%2F2017%2F04%2F20%2F20170420-spark-error%2F</url>
    <content type="text"><![CDATA[¶1、错误日志： 1error: not found: value StorageLevel ¶2、场景描述： 数据持久化的时候 ¶3、错误原因： 没有引用StorageLevel ¶4、解决办法： import org.apache.spark.storage.StorageLevel]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark error：not found：value sqlContext]]></title>
    <url>%2F2017%2F04%2F19%2F20170419-spark-error-01%2F</url>
    <content type="text"><![CDATA[记录一下遇到过的错误。 ¶1、错误日志： 12345&lt;console&gt;:10: error: not found: value sqlContext import sqlContext.implicits._ ^&lt;console&gt;:10: error: not found: value sqlContext import sqlContext.sql ¶2、场景描述： spark-shell进入后，报出的错误。 ¶3、错误原因： 由于没有spark-shell不会自动创建sqlContext，pyspark会自动创建 ¶4、解决办法： 初始化sqlContext，如下： 12345import org.apache.spark.SparkConfimport org.apache.spark.SparkContextimport org.apache.spark.SparkContext._val conf = new SparkConf().setMaster(&quot;local&quot;).setAppName(&quot;My App&quot;)val sc = new SparkContext(conf)]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[spark error：Address already in use]]></title>
    <url>%2F2017%2F04%2F19%2F20170419-spark-error-02%2F</url>
    <content type="text"><![CDATA[¶1、错误日志： 12345Address already in useorUtils: Service &apos;SparkUI&apos; could not bind on port 4040. Attempting port 4041. ¶2、场景描述： 初始化sqlContext的时候 ¶3、错误原因： 每一个Spark任务都会占用一个SparkUI端口，默认为4040，如果被占用则依次递增端口重试。但是有个默认重试次数，重试都失败后，会放弃该任务的运行 ¶4、解决办法： 初始化SparkConf时，添加conf.set(“spark.port.maxRetries”,“100”)语句 使用spark-submit提交任务时，在命令行中添加-Dspark.port.maxRetries=100 在spark-defaults.conf中添加spark.port.maxRetries 100]]></content>
      <categories>
        <category>spark</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hbase error：Caught throwable while processing event M_SERVER_SHUTDOWN]]></title>
    <url>%2F2017%2F04%2F13%2F20170413-hbase-error%2F</url>
    <content type="text"><![CDATA[¶1、错误日志： 1Caught throwable while processing event M_SERVER_SHUTDOWN ¶2、场景描述： 集群能正常启动，但是hbase master启动后过会就挂掉了 ¶3、解决办法： 删除hdfs上hbase根目录下的WALs文件夹]]></content>
      <categories>
        <category>hbase</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>hbase</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[arch在64位系统上运行和编译32位程序]]></title>
    <url>%2F2017%2F03%2F31%2F20170331-arch%E5%9C%A864%E4%BD%8D%E7%B3%BB%E7%BB%9F%E4%B8%8A%E8%BF%90%E8%A1%8C%E5%92%8C%E7%BC%96%E8%AF%9132%E4%BD%8D%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[¶1、问题 由于一些情况，需要使用wine。而wine又是32位程序，如果直接用yaourt会报错一些错误：lib target not found （各种lib32-xxx等等） ¶2、原因 arch64位系统默认是关闭Multilib仓库的. arch官方的一些对Multilib一些解释： multilib 仓库让用户可以在 64 位 Arch Linux 系统上运行和编译 32 位程序。 启用 multilib 的 64 位系统使用了类似 Debian 的目录结构。 32位库位于 /usr/lib32/, 而64位库位于/usr/lib/. ¶3、解决 编辑/etc/pacman.conf,取消下面内容的注释 [multilib] Include = /etc/pacman.d/mirrorlist 更多详情参考:arch官方wiki]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[初识arch]]></title>
    <url>%2F2017%2F03%2F30%2F20170330-%E5%88%9D%E8%AF%86arch%2F</url>
    <content type="text"><![CDATA[之前一直用centos系统，由于与服务器一致。后面发现日常用还是不够理想，后面来换arch。发现一个作者的几篇文章不错，收藏一下。由于作者谢绝转载。 以下为访问地址： https://github.com/LinuxTOY/linuxtoy.org/blob/master/content/the-perfect-linux-desktop-arch-linux-2007-08-2-1.md https://github.com/LinuxTOY/linuxtoy.org/blob/master/content/the-perfect-linux-desktop-arch-linux-2007-08-2-2.md https://github.com/LinuxTOY/linuxtoy.org/blob/master/content/the-perfect-linux-desktop-arch-linux-2007-08-2-3.md https://github.com/LinuxTOY/linuxtoy.org/blob/master/content/the-perfect-linux-desktop-arch-linux-2007-08-2-4.md https://github.com/LinuxTOY/linuxtoy.org/blob/master/content/the-perfect-linux-desktop-arch-linux-2007-08-2-5.md]]></content>
      <categories>
        <category>arch</category>
      </categories>
      <tags>
        <tag>arch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cdh修改hadoop集群的IP]]></title>
    <url>%2F2017%2F02%2F27%2F20170227-Cloudera-Manager%E4%BF%AE%E6%94%B9%E9%9B%86%E7%BE%A4%E7%9A%84IP%2F</url>
    <content type="text"><![CDATA[测试机器没有放在机房，跟着我走的。由于一些情况，搬位置了，ip也随之变化。不过也好，正好学习下。 不废话了，直接记录操作的过程 ¶1、停止各个机器上的相关服务 12service cloudera-scm-agent stop service cloudera-scm-server stop ¶2、修改托管服务数据库中的配置 修改HOSTS 表中的 ip_adderss ¶3、修改config.ini 修改clouder-mager服务机器上面config.ini中：server_host 123456789#vi /etc/cloudera-scm-agent/config.ini[General]# Hostname of the CM server.server_host=172.16.8.202# Port that the CM server is listening on.server_port=7182...... ¶4、修改hosts 修改hosts，并scp到其他机器 12345678910111213141516171819# vi /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6172.16.8.201 kvm172.16.8.202 cdh.scm172.16.8.203 cdh.master172.16.8.204 cdh.slave01172.16.8.205 cdh.slave02172.16.8.206 cdh.slave03[root@kvm ~]# scp /etc/hosts 172.16.3.202:/etc/hostsThe authenticity of host '172.16.3.202 (172.16.3.202)' can't be established.RSA key fingerprint is a2:84:e0:da:bf:a9:a2:83:5f:d0:d0:a2:04:02:eb:cb.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added '172.16.3.202' (RSA) to the list of known hosts.root@172.16.3.202's password: hosts 100% 298 0.3KB/s 00:00 ¶5、启动各个机器上的相关服务 12service cloudera-scm-agent startservice cloudera-scm-server start 启动过程可能有点慢，可以查看日志，当出现了以下即可： 12345# tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log2017-02-24 21:38:36,288 INFO WebServerImpl:org.mortbay.log: jetty-6.1.26.cloudera.42017-02-24 21:38:36,296 INFO WebServerImpl:org.mortbay.log: Started SelectChannelConnector@0.0.0.0:71802017-02-24 21:38:36,297 INFO WebServerImpl:com.cloudera.server.cmf.WebServerImpl: Started Jetty server. ¶6、运行升级向导 安装下图进行升级向导 等待一会就好，如果有错误看错误日志。 ¶7、更新配置文件 ¶7.1 更新clouder magerment service 过去配置 ¶7.2 更新集群过期配置 等待一会就好 ¶8、完成并测试一下 随便测试一下好了，就hive吧 ok]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>hadoop</tag>
        <tag>cdh</tag>
        <tag>cloudera-manger</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hive-server2 join的问题]]></title>
    <url>%2F2017%2F02%2F21%2F20170221-hiveserver2-join%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[很奇怪的一天，hive命令行执行就正常,hive-server2执行就报错。以下是我的问题记录以及谷歌到的解决办法。 ¶1、问题描述 hive客户端在执行带有join语句的时候,会报错： ¶1.1 控制台报的错 1Error: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask (state=08S01,code=1) ¶1.2 hive-server2.log 日志文件中报的错 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647482017-02-21 15:15:41,689 ERROR [HiveServer2-Background-Pool: Thread-2064]: mr.MapredLocalTask (MapredLocalTask.java:executeInChildVM(318)) - Exception: java.io.IOException: Cannot run program "/usr/lib/hadoop/bin/hadoop" (in directory "/root"): error=13, Permission deniedjava.io.IOException: Cannot run program "/usr/lib/hadoop/bin/hadoop" (in directory "/root"): error=13, Permission denied at java.lang.ProcessBuilder.start(ProcessBuilder.java:1047) at java.lang.Runtime.exec(Runtime.java:617) at java.lang.Runtime.exec(Runtime.java:450) at org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.executeInChildVM(MapredLocalTask.java:291) at org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask.execute(MapredLocalTask.java:140) at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:160) at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:88) at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1638) at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1398) at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1182) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1048) at org.apache.hadoop.hive.ql.Driver.run(Driver.java:1043) at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:144) at org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:69) at org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:196) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671) at org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:208) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745)Caused by: java.io.IOException: error=13, Permission denied at java.lang.UNIXProcess.forkAndExec(Native Method) at java.lang.UNIXProcess.&lt;init&gt;(UNIXProcess.java:186) at java.lang.ProcessImpl.start(ProcessImpl.java:130) at java.lang.ProcessBuilder.start(ProcessBuilder.java:1028) ... 23 more2017-02-21 15:15:41,690 ERROR [HiveServer2-Background-Pool: Thread-2064]: ql.Driver (SessionState.java:printError(921)) - FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask2017-02-21 15:15:41,690 ERROR [HiveServer2-Background-Pool: Thread-2064]: operation.Operation (SQLOperation.java:run(199)) - Error running hive query: org.apache.hive.service.cli.HiveSQLException: Error while processing statement: FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.mr.MapredLocalTask at org.apache.hive.service.cli.operation.Operation.toSQLException(Operation.java:315) at org.apache.hive.service.cli.operation.SQLOperation.runQuery(SQLOperation.java:146) at org.apache.hive.service.cli.operation.SQLOperation.access$100(SQLOperation.java:69) at org.apache.hive.service.cli.operation.SQLOperation$1$1.run(SQLOperation.java:196) at java.security.AccessController.doPrivileged(Native Method) at javax.security.auth.Subject.doAs(Subject.java:415) at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1671) at org.apache.hive.service.cli.operation.SQLOperation$1.run(SQLOperation.java:208) at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471) at java.util.concurrent.FutureTask.run(FutureTask.java:262) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615) at java.lang.Thread.run(Thread.java:745) ¶2、分析以及解决 首先注意到是MapredLocalTask，开启了本地模式。那关闭本地模式试一下， 1set hive.exec.mode.local.auto=false; 结果还是报相同错误，只能从其他方面考虑。 在默认情况下，hive的join策略是进行reduce side join，但是当两个表中有一个是小表的时候，就会使用map join，把其中较小的一个表复制到所有节点，这样另一个表在每个节点上面的分片就可以跟这个完整的表join。 分析这个问题，job使用map join时可能造成内存溢出，关闭其自动装换尝试一下。 1set hive.auto.convert.join = false; 果然ok了。 参考]]></content>
      <categories>
        <category>hive</category>
      </categories>
      <tags>
        <tag>hive</tag>
        <tag>hive-server2</tag>
        <tag>join</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python lxml安装报错]]></title>
    <url>%2F2017%2F02%2F15%2F20170215-python-lxml%E5%AE%89%E8%A3%85%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[¶1、安装lxml时报错 1pip install lsml 错入信息如下： ¶2、安装libxml2 1yum install libxml2 ¶3、重新安装lxml 1sudo pip install lxml 结果还是提示相同的错误信息。 ¶4、检查是否安装 libxml2-dev、 libxslt-devel 12##同时安装依赖 libxml2-develyum install libxslt-devel ¶5、再次安装lxml 1sudo pip install lxml 安装成功。]]></content>
      <categories>
        <category>python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>lxml</tag>
        <tag>libxml2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centOS彻底卸载wine]]></title>
    <url>%2F2017%2F01%2F23%2F20170123-CentOS%E5%BD%BB%E5%BA%95%E5%8D%B8%E8%BD%BDwine%2F</url>
    <content type="text"><![CDATA[报错了：wine: ‘/root/.wine’ is a 64-bit installation, it cannot be used with a 32-bit wineserver. 怀疑是多次安装导致的，先卸载吧 ¶1. 卸载wine及相关组件 12yum remove wine*yum autoremove ¶2. 删除相关文件 123~/.wine~/.local/share/applications/usr/lib/wine ¶3. 搜索删除，然后根据情况删除 1find / -name *wine*]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>wine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2016已经过去 2017正在进行]]></title>
    <url>%2F2017%2F01%2F18%2F20170118-2016%E5%B7%B2%E7%BB%8F%E8%BF%87%E5%8E%BB-2017%E6%AD%A3%E5%9C%A8%E8%BF%9B%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[¶1、开头语 沉醉在代码的世界里面，日子总是过的很快，一不留神就到了2017。一直想着写点什么，又一直没有停下来好好得思考一下。 ¶2、2016 写之前想了好多，可是当写的时候又不知道写什么了。 ¶2.1 工作 从重庆到了上海，然后工作了3个月不到换到现在这家公司。当时还是考虑了好久的。 sdf 算了，确实不知道怎么写了，明天在写吧。额，好像明天公司聚餐。后天写吧。先下班了]]></content>
      <categories>
        <category>随想</category>
      </categories>
      <tags>
        <tag>随想</tag>
        <tag>总结</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OmniMarkupPreviewer的实时预览无法使用问题的解决]]></title>
    <url>%2F2017%2F01%2F18%2F20170118-OmniMarkupPreviewer%E7%9A%84%E5%AE%9E%E6%97%B6%E9%A2%84%E8%A7%88%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[突然就不行了，重装也不行。后面谷歌到了,记录一下。懒的截图，图片也借用下 ¶1、问题描述 Sublime下采用Package Control安装好OmniMarkupPreviewer，使用一段时间后，突然无法实现Markdown文件实时预览功能。 谷歌访问效果如下： ¶2、原因 Ctrl+ 打开控制台，查看日志信息，下面是我的日志信息： 123456789101112131415161718192021222324252627&lt;code&gt;&lt;code&gt;OmniMarkupPreviewer: [INFO] Launching web browser for http://127.0.0.1:51004/view/29UnicodeEncodeError(&apos;latin-1&apos;, &apos;夏至&apos;, 0, 2, &apos;ordinal not in range(256)&apos;)Traceback (most recent call last): File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 1035, in communicate req.respond() File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 831, in respond self.server.gateway(self).respond() File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 1868, in respond self.write(chunk) File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 1934, in write self.req.send_headers() File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 941, in send_headers (b&quot;Server&quot;, self.server.server_name.encode(&apos;ISO-8859-1&apos;)))UnicodeEncodeError: &apos;latin-1&apos; codec can&apos;t encode characters in position 0-1: ordinal not in range(256)UnicodeEncodeError(&apos;latin-1&apos;, &apos;夏至&apos;, 0, 2, &apos;ordinal not in range(256)&apos;)Traceback (most recent call last): File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 1035, in communicate req.respond() File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 831, in respond self.server.gateway(self).respond() File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 1868, in respond self.write(chunk) File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 1934, in write self.req.send_headers() File &quot;C:\Users\xiazhi\AppData\Roaming\Sublime Text 3\Packages\OmniMarkupPreviewer\OmniMarkupLib\libs\cherrypy\wsgiserver\wsgiserver3.py&quot;, line 941, in send_headers (b&quot;Server&quot;, self.server.server_name.encode(&apos;ISO-8859-1&apos;)))&lt;/code&gt;&lt;/code&gt; 其中 UnicodeEncodeError('latin-1', '夏至', 0, 2, 'ordinal not in range(256)')为报错信息。夏至是计算机名。 ¶3、解决 修改一下计算机名字 最终结果，可以正常显示了。 转载出处：点击前往]]></content>
      <categories>
        <category>ide</category>
      </categories>
      <tags>
        <tag>OmniMarkupPreviewer</tag>
        <tag>sublime text</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos无线网连接问题]]></title>
    <url>%2F2017%2F01%2F10%2F20170110-centos%E6%97%A0%E7%BA%BF%E7%BD%91%E8%BF%9E%E6%8E%A5%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[最近电脑越来越卡，正好想彻底的学习一下centos.就把笔记本的系统换成centos了。由于笔记本嘛，肯定用无线网了方便、简洁。 ¶1、问题描述 因为是日常娱乐使用，安装的时候选择的是桌面版。安装后有网卡驱动。但是在使用的是网络偶尔能连上，一直断。 ¶2、问题原因 网上找了一些资料，一些说是没有安装驱动，一些说没有安装正确对应的无线网卡驱动。 ¶1.2 基本参数 iwconfig可以查看无线网卡的具体型号,lspci |grep -i network 查看网卡具体型号]]></content>
      <categories>
        <category>centos</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[centos设置ntp服务器和客户端]]></title>
    <url>%2F2016%2F12%2F07%2F20161207-centos%E8%AE%BE%E7%BD%AEntp%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[NTP（Network Time Protocol）是用来使计算机时间同步化的一种协议，它可以使计算机对其服务器或时钟源做同步化，它可以提供高精准度的时间校正。本例讲解如何在CentOS6.3上配置NTP服务器和NTP客户端，可使多台客户机的时间与指定的NTP服务器的时间保持一致。从而保证了多台服务器的时间同步。 ¶1、安装ntp和修改时区 简单点之间用yum安装 123yum -y install ntpcp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime ¶2、设置服务端192.168.0.25 修改/etc/ntp.cnf 12345678910#限定了哪些主机可以从本NTP服务器同步时间，默认的配置文件里是没有这句话的。加入这句话后，表明，只有192.168.0 这个网段的主机可以从本NTP服务器同步时间。nomodify 表明客户端不可以修改服务器的地址restrict 192.168.0.1/24 mask 255.255.255.0 nomodify #远程服务器地址server time-b.nist.gov#默认的配置文件里这两个是被注释掉的。如果第二部配置的server time-b.nist.gov无效时，则NTP服务器会根据这里的配置，把自己的时间做为NTP服务器的时间，即和自己同步。考虑到有的局域网里不可以访问外网，所有这里需要把这个配置项用上，即把前面的注释符#号去掉就可以了。server 127.127.1.0 # local clock fudge 127.127.1.0 stratum 10 记着关闭防火墙或者开放123/udp端口 重启服务servcice ntpd resatrt NTP服务启动后大约需要3～5分钟的时间才会进行一次时间同步。可以通过命令ntpstat查看同步情况， ¶3、设置客户端 修改/etc/ntp.cnf 1server 192.168.0.25 然后重启服务service ntpd resatrt ¶4、相关命令 查看系统时间：date 查看与上层ntp服务器的关系：ntpq -p 查看是否更新了自己的时间：ntpstat]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>ntp</tag>
        <tag>服务端</tag>
        <tag>客户端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[cdh搭建hadoop集群-hive错误集]]></title>
    <url>%2F2016%2F12%2F06%2F20161206-cdh%E6%90%AD%E5%BB%BAhadoop%E9%9B%86%E7%BE%A4-hive%E9%94%99%E8%AF%AF%E9%9B%86%2F</url>
    <content type="text"><![CDATA[¶1、Specified key was too long; max key length is 767 bytes 1create database hive DEFAULT CHARSET latin1; 这里由于mysql的最大索引长度导致，MySQL的varchar主键只支持不超过768个字节 或者 768/2=384个双字节 或者 768/3=256个三字节的字段 而 GBK是双字节的，UTF-8是三字节的 解决办法：数据库的字符集除了system为utf8，其他最好为latin1，否则可能出现如上异常，在mysql机器的上运行: ¶2、javax.jdo.JDODataStoreException: Error executing SQL query “select “DB_ID” from “DBS”” 原因：很简单，就是没有创建存放hive元数据的表。在CDH页面找了很久，发现配置也正确也能正常连接上但是就是不能自动创建 解决办法：/opt/cloudera/parcels/CDH-5.4.2-1.cdh5.4.2.p0.2/lib/hive/scripts/metastore/upgrade/mysql/ 里面是mysql的相关的sql脚本，直接拿到mysql执行。]]></content>
      <categories>
        <category>hive</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[centos更改国内阿里的yum源]]></title>
    <url>%2F2016%2F12%2F01%2F20161201-centos%E6%9B%B4%E6%94%B9%E5%9B%BD%E5%86%85%E9%98%BF%E9%87%8C%E7%9A%84yum%E6%BA%90%2F</url>
    <content type="text"><![CDATA[阿里云是最近新出的一个镜像源。得益与阿里云的高速发展，这么大的需求，肯定会推出自己的镜像源。 阿里云Linux安装镜像源地址：http://mirrors.aliyun.com/ CentOS系统更换软件安装源 ¶第一步：备份你的原镜像文件，以免出错后可以恢复。 1mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup ¶第二步：下载新的CentOS-Base.repo 到/etc/yum.repos.d/ 1234CentOS 5wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repoCentOS 6wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo ¶第三步：运行yum makecache生成缓存 12yum clean allyum makecache]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>国内</tag>
        <tag>阿里</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用工具大集合(突发奇想更新中...)]]></title>
    <url>%2F2016%2F11%2F21%2F20161121-%E5%B8%B8%E7%94%A8%E5%B7%A5%E5%85%B7%E5%A4%A7%E9%9B%86%E5%90%88-%E7%AA%81%E5%8F%91%E5%A5%87%E6%83%B3%E6%9B%B4%E6%96%B0%E4%B8%AD%2F</url>
    <content type="text"><![CDATA[由于有的时候会忘记，先记录下。方便以后好查 ¶1、效率 ¶1.1 日常 小Q书桌：快捷方式管理 LICEcap：快速录像并生产gif Everything：文件快速搜索、查找 sublime：文件编辑器 BCompare：文件比对，文件夹比对 SpaceSniffer：查询硬盘占用比例 filezilla：ftp工具 SecureCRT：虚拟终端工具 ¶1.2 GTD 滴答清单：事件清单。记录待办事件 ¶1.3 插件 vimium：浏览器控制插件，代替鼠标 lastpass: 密码管理器 ¶2、 网络 净网大师：拦截、劫持广告 Shadowsocks：翻墙梯子 非凡vpn：每天免费1小时 ¶3、工作 ¶3.1 数据库 filezilla：ftp工具 Dbvisualizer: 关系型数据库sql客户端]]></content>
      <categories>
        <category>常用</category>
      </categories>
      <tags>
        <tag>常用</tag>
        <tag>常用工具</tag>
        <tag>集合</tag>
        <tag>大集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[亚马逊aws更改linux为root权限密码登陆]]></title>
    <url>%2F2016%2F11%2F21%2F20161121-%E4%BA%9A%E9%A9%AC%E9%80%8Aaws%E6%9B%B4%E6%94%B9linux%E4%B8%BAroot%E6%9D%83%E9%99%90%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86%2F</url>
    <content type="text"><![CDATA[我的AWS VPS的LINUX版本是centos6.5 ，首先用AWS证书验证的账户登录. ¶1、修改ROOT密码 1sudo passwd root ¶2、修改sshd_config文件 12345sudo vi /etc/ssh/sshd_config#修改这2行PermitRootLogin yesPasswordAuthentication yes ¶3、重启ssh就可以使用root正常登陆了 1/sbin/service sshd restart ¶4、登录工具 pc可以使用：SecureCRT 手机可以使用：Serverauditor]]></content>
      <categories>
        <category>aws</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>linux</tag>
        <tag>aws</tag>
        <tag>亚马逊</tag>
        <tag>root登录</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ss用一段时间卡？vps定时重启试试]]></title>
    <url>%2F2016%2F11%2F21%2F20161121-ss%E7%94%A8%E4%B8%80%E6%AE%B5%E6%97%B6%E9%97%B4%E5%8D%A1%EF%BC%9Fvps%E5%AE%9A%E6%97%B6%E9%87%8D%E5%90%AF%E8%AF%95%E8%AF%95%2F</url>
    <content type="text"><![CDATA[用了半个月的ss后，速度变的相当慢。找了各种办法，无解。后来重启后速度又杠杠的跑了起来。 ¶1. 添加定时重启vps 1234crontab -e #编辑任务列表#新增：注意用root用户添加 01 21 * * * /sbin/roboot #由于vps的时间要晚8个小时，又懒得去修改时间就这样吧。 ¶2. 开机自动启动ss服务等 123456# ss的开机启动 chkconfig supervisord on# 锐速开机启动 chkconfig serverSpeeder on# net-speeder的开机启动 echo 'nohup /usr/local/net_speeder/net_speeder eth0 "ip" &gt;/var/log/net_speeder 2&gt;&amp;1 &amp;' &gt;&gt; /etc/rc.local ¶3.补充：Crontab基本格式： 12* * * * * command分 时 日 月 周 命令]]></content>
      <categories>
        <category>ss</category>
      </categories>
      <tags>
        <tag>vps</tag>
        <tag>ss</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给VMware下的Linux扩展磁盘空间（以CentOS6.3为例）]]></title>
    <url>%2F2016%2F11%2F17%2F20161117-%E7%BB%99VMware%E4%B8%8B%E7%9A%84Linux%E6%89%A9%E5%B1%95%E7%A3%81%E7%9B%98%E7%A9%BA%E9%97%B4%2F</url>
    <content type="text"><![CDATA[前提是使用的lvm逻辑卷分区，才能这样扩展。 查看挂载点： 1234567df -h#显示： 文件系统 容量 已用 可用 已用%% 挂载点 /dev/mapper/vg_dc01-lv_root 47G 12G 34G 25% /tmpfs 504M 88K 504M 1% /dev/shm/dev/sda1 485M 31M 429M 7% /boot ¶一、扩展VMWare硬盘空间 关闭Vmware 的 Linux系统，这样，才能在VMWare菜单中设置： 1 VM -&gt; Settings... -&gt; Hardware -&gt; Hard Disk -&gt; Utilities -&gt; Expand 输入你想要扩展到多少G。本文假设你新增加了 30G ¶二、对新增加的硬盘进行分区、格式化 这里进行一个极简化的介绍，非常简化，但很全面，上面已经知道增加了空间的硬盘是 /dev/sda。 12345678910111213141516#分区：fdisk /dev/sda #操作 /dev/sda 的分区表p #查看已分区数量（我看到有两个 /dev/sda1 /dev/sda2）n #新增加一个分区p #分区类型我们选择为主分区3 #分区号选3（因为1,2已经用过了，见上）回车 #默认（起始扇区）回车 #默认（结束扇区）t #修改分区类型3 #选分区8e #修改为LVM（8e就是LVM）w #写分区表q #完成，退出fdisk命令#系统提示你重启，重启吧.#开机后，格式化：mkfs.ext3 /dev/sda3 ##三、添加新LVM到已有的LVM组，实现扩容 123456lvm 进入lvm管理lvm&gt; pvcreate /dev/sda3 这是初始化刚才的分区，必须的lvm&gt; vgextend vg_dc01 /dev/sda3 将初始化过的分区加入到虚拟卷组vg_dc01lvm&gt;lvextend -L +29.9G /dev/vg_dc01/lv_root 扩展已有卷的容量（29.9G这个数字在后面解释）lvm&gt;pvdisplay 查看卷容量，这时你会看到一个很大的卷了lvm&gt;quit 退出 上面那个 29.9G 怎么来的呢？因为你在VMWare新增加了30G，但这些空间不能全被LVM用了，你可以在上面的lvextend操作中一个一个的试探，比如 29.9G, 29.8G … 直到不报错为止，这样你就可以充分使用新增加的硬盘空间了，当然这是因为我不懂才用的笨办法，高手笑笑就过了吧。（我更不懂啊，原作者，我直接上了29.9G，结果就OK了） 以上只是卷扩容了，下面是文件系统的真正扩容，输入以下命令： 1234resize2fs /dev/vg_dc01/lv_root#再运行下：df -h 查看下我们机器性感的硬盘吧。]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>vm</tag>
        <tag>centos</tag>
        <tag>lvm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos下mysqld的service服务]]></title>
    <url>%2F2016%2F11%2F16%2F20161116-centos%E4%B8%8Bmysqld%E7%9A%84service%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[linux下有的软件启动很麻烦，跟一大堆参数，比如指定配置文件路径、以何种模式启动神马的，等等。而我们装上appache或者mysql后，就可以使用service httpd start来启动，很是方便，service命令其实是跑一个shell脚本来管理，这样的话，我们自己手动写个shell脚本就可以实现service anything doanything了。另外，用chkconfig命令设置开机自动启动一个服务，该服务必须是系统服务，否则用chkconfig设置是会报错的。这样的话，把一些服务注册为系统服务，确实还是蛮必须的。而注册成系统服务，就是这个service… 当我们输入service命令时，linux会去/etc/rc.d/init.d下去找这个脚本运行。init.d下面放的就是很多脚本，比如service svnd start时，就去/etc/rc.d/init.d下找svnd这个脚本文件，如果这个文件不存在，则会提示不存在这个服务。所以，这个就好办了，只要在init.d目录下写个脚本，就可以用service命令在任何地方执行了。 ¶1. centos注册mysql服务 在/etc/init.d/目录下创建mysql的脚本：`` 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121#!/bin/bash##################################################### MySQL start and stop script#####################################################basedir=/home/falcon/mysqldatadir=/home/falcon/mysql/3306conf=$basedir/etc/3306.cnfmysql_user=falcon###################################################bindir=$basedir/binserver_pid_file=$datadir/`/bin/hostname`.pidpid_file=$server_pid_fileother_args="--user=$mysql_user"PATH=/sbin:/usr/sbin:/bin:/usr/bin:$basedir/binexport PATHmode=$1 # start or stopshift## Use LSB init script functions for printing messages, if possible#lsb_functions="/lib/lsb/init-functions"if test -f $lsb_functions ; then source $lsb_functionselse log_success_msg() &#123; echo " SUCCESS! $@" &#125; log_failure_msg() &#123; echo " ERROR! $@" &#125;fiwait_for_pid () &#123; i=0 while test $i -lt 35 ; do sleep 1 case "$1" in 'created') test -s $pid_file &amp;&amp; i='' &amp;&amp; break ;; 'removed') test ! -s $pid_file &amp;&amp; i='' &amp;&amp; break ;; *) echo "wait_for_pid () usage: wait_for_pid created|removed" exit 1 ;; esac echo $echo_n ".$echo_c" i=`expr $i + 1` done if test -z "$i" ; then log_success_msg else log_failure_msg fi&#125;# Safeguard (relative paths, core dumps..)cd $basedircase "$mode" in 'start') # Start daemon if test -s "$server_pid_file" thenecho "MySQL is running now ..."exit 1 fi echo $echo_n "Starting MySQL" if test -x $bindir/mysqld_safe then # Give extra arguments to mysqld with the my.cnf file. This script # may be overwritten at next upgrade. pid_file=$server_pid_file $bindir/mysqld_safe --defaults-file=$conf --datadir=$datadir --pid-file=$server_pid_file $other_args &gt;/dev/null 2&gt;&amp;1 &amp; wait_for_pid created else log_failure_msg "Couldn't find MySQL manager or server" fi ;; 'stop') # Stop daemon. We use a signal here to avoid having to know the # root password. if test -s "$pid_file" then mysqlmanager_pid=`cat $pid_file` echo $echo_n "Shutting down MySQL" kill $mysqlmanager_pid # mysqlmanager should remove the pid_file when it exits, so wait for it. wait_for_pid removed else log_failure_msg "MySQL manager or server PID file could not be found!" fi ;; 'restart') # Stop the service and regardless of whether it was # running or not, start it again. $0 stop $other_args $0 start $other_args ;; 'reload') if test -s "$server_pid_file" ; then mysqld_pid=`cat $server_pid_file` kill -HUP $mysqld_pid &amp;&amp; log_success_msg "Reloading service MySQL" touch $server_pid_file else log_failure_msg "MySQL PID file could not be found!" fi ;; *) # usage echo "Usage: $0 &#123;start|stop|restart|reload&#125; [ MySQL server options ]" exit 1 ;;esac 简化版的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758 #!/bin/bash#######################################################basedir=/home/falcon/mysqldatadir=/home/falcon/data/10000conf=$basedir/etc/10000.cnf#######################################################pid_file=$datadir/`/bin/hostname`.pidMYSQLD="$basedir/bin/mysqld_safe --defaults-file=$conf"usage()&#123; echo "usage:" echo " $0 start|stop|status " exit 1&#125;if test -z $1then usagefiSTATUS=$pid_filecase "$1" in "start") if test -s "$STATUS" then echo "The MySQL is running ..." echo $pid_file exit 1 fi if test -s "$STATUS" then echo "The MySQL start fail ..." else $MYSQLD &gt; /dev/null 2&gt;&amp;1 &amp; fi ;; "stop") pid=`cat $pid_file` `kill $pid &gt; /dev/null 2&gt;&amp;1` echo "The MySQL is stop ..." ;; "reload") pid=`cat $pid_file` `kill -HUP $pid &gt; /dev/null 2&gt;&amp;1` ;; "status") if test -s "$STATUS" then echo "The MySQL is running..." else echo "The MySQL is down..." fi ;; *) usage ;;esacexit 1 ¶2. 设置 对文件添加可执行权限chmod +x mysqld ¶3. 测试 1servcie mysqld status ¶4. 设置chkconfig 在脚本的前面几行加入下面句话，开头带# 12# chkconfig: 2345 08 92# description: Starts, stops and saves iptables firewall ¶5. 开机自动启动 1chkconfig mysqld on]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>centos</tag>
        <tag>mysqld</tag>
        <tag>service</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卸载CDH（Cloudera Manager 和托管软件）]]></title>
    <url>%2F2016%2F11%2F14%2F20161114-%E5%8D%B8%E8%BD%BDCDH%EF%BC%88Cloudera-Manager-%E5%92%8C%E6%89%98%E7%AE%A1%E8%BD%AF%E4%BB%B6%EF%BC%89%2F</url>
    <content type="text"><![CDATA[¶1. 一些默认的地址 12345678910/var/lib/flume-ng /var/lib/hadoop* /var/lib/hue /var/lib/navigator /var/lib/oozie /var/lib/solr /var/lib/sqoop* /var/lib/zookeeper /dfs /mapred /yarn ¶2. 恢复未完成的安装 1rm -Rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/cloudera* ¶2. 停止各种cdh和cm服务 可以直接在界面上面定制 ¶3. 删除cm server上的服务及安装 123456service cloudera-scm-server stopservice cloudera-scm-server-db stopservice cloudera-scm-agent hard_stopyum remove 'cloudera-manager-*'yum clean all ¶4. 手动删除数据文件 ¶4.1 删除 Cloudera Manager 数据 1rm -Rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/cloudera* /var/log/cloudera* /var/run/cloudera* ¶4.2 删除 Cloudera Manager 锁定文件 1rm /tmp/.scm_prepare_node.lock ¶4.3 删除用户数据 12rm -Rf /var/lib/flume-ng /var/lib/hadoop* /var/lib/hue /var/lib/navigator /var/lib/oozie /var/lib/solr /var/lib/sqoop* /var/lib/zookeeperrm -Rf /dfs /mapred /yarn ¶5. 快速操作 1234567891011121.service cloudera-scm-server stopservice cloudera-scm-server-db stopservice cloudera-scm-agent hard_stopyum remove 'cloudera-manager-*'yum remove enterprise*2.rm -Rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/cloudera* /var/log/cloudera* /var/run/cloudera*rm /tmp/.scm_prepare_node.lockrm -Rf /var/lib/flume-ng /var/lib/hadoop* /var/lib/hue /var/lib/navigator /var/lib/oozie /var/lib/solr /var/lib/sqoop* /var/lib/zookeeperrm -Rf /dfs /mapred /yarn]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>卸载CDH</tag>
        <tag>cloudera</tag>
        <tag>cdh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos源码安装mysql5.1.28]]></title>
    <url>%2F2016%2F11%2F14%2F20161114-centos%E6%BA%90%E7%A0%81%E5%AE%89%E8%A3%85mysql%2F</url>
    <content type="text"><![CDATA[¶1. centos配置 ¶1.1 安装需要用到的软件 ncurses-devel：编译的时候需要，没有的话：configure: error: No curses/termcap library found gcc-c++：安装的时候需要，没有的话：…/depcomp: line 512: exec: g++: not found 1yum -y install gcc-c++ ncurses-devel ¶1.2 创建mysql 用户 12groupadd mysqluseradd -g mysql mysql ¶2. 下载 下载mysql的安装包 ** 5.1版本以前用configure进行编译，5.1之后的版本用cmake进行编译。** ¶3. 解压安装 ¶3.1 解压 解压到/opt目录下 1tar -axvf mysql-5.1.28-rc.tar.gz -C /opt ¶3.2 编译 –prefix：安装目录 –with-charset：字符集编码 –with-plugins：存储引擎 1./configure --prefix=/opt/mysql --with-charset=utf8 --with-plugins=innobase ¶3.3 安装 12makemake install ¶4. 配置与初始化 ¶4.1 修改my.cnf 系统默认是按/etc/my.cnf-----/etc/mysql/my.cnf----/opt/mysql/my.cnf的顺序读取配置文件的，当有多个配置文件时，mysql会以读取到的最后一个配置文件中的参数为准。 具体优化就不说了，这里就基本配置。 在安装目录下share/mysql/ 下找到my-medium.cnf,，将它拷贝到安装目录并且重命名为my.cnf 1234# 修改下面3个参数 /opt/mysql 为安装目录datadir=/opt/mysql/varsocket=/opt/mysql/mysql.sockbasedir=/opt/mysql ¶4.2 mysql服务启动脚本 1234567891011cp share/mysql/mysql.server /etc/init.d/mysqldchmod 755 /etc/init.d/mysqldchkconfig mysqld on``` ### 4.3 初始化数据库表```bashchown mysql.mysql -R /opt/mysql# datadir目录不能有数据./bin/mysql_install_db --user=mysql --datadir=/opt/mysql/var ¶4.4 启动数据库 1234./bin/mysqld_safe --defaults-file=/opt/mysql/my.cnf# 如果报错要学会看错误日志：more /opt/mysql/var/cdh.scm.err ¶4.5 修改密码并进入数据库 12./bin/mysqladmin -h '127.0.0.1' -u root password 123./bin/mysql -h '127.0.0.1' -u root -p ¶5. 可能遇到的错误 ¶5.1 fatal error: Can’t change to run as user ‘mysql’ ; Please check that the user exists! 1rm -rf /etc/my.cnf 然后在重新初始化数据库表 ok 成功 ¶5.2 unknown option ‘–skip-federated’ 将my.cnf文件中的skip-federated注释掉即可 ¶5.3 ERROR 2002 (HY000): Can’t connect to local MySQL server through socket /tmp/mysql.sock 1234561、执行 sudo ln -s /opt/mysql/mysql.sock /tmp/mysql.sock 2、将连接mysql的语句改成 mysql -h 127.0.0.1 -u root -pmysql使用unix socket或者tcp来连接数据库进行通讯，默认不加 -h选项时使用的就是localhost即unixsocket，此时会通过/tmp/mysql.sock来通讯，但是在配置文件中默认生成的socket文件是在/var/lib/mysql/mysql.sock(不同安装可能不同，建议查看/etc/my.cnf确认),所以要想mysql使用这个文件通讯，最简单的方法就是建立软链接，一劳永逸，此为方法一方法二就是强制mysql使用tcp通讯，因为127.0.0.1对于mysql来说走的是tcp协议而非unixsocket，这种方法的弊端就是每次都要指明本地地址127.0.0.1 ¶5.4 [ERROR] Can’t start server: can’t create PID file: No such file or directory pid的路径必须存在，mysql不会自动创建。自己手动把路径建好就好了 ¶5.5 [ERROR] /opt/mysql/libexec/mysqld: unknown option ‘–skip-federated’ 删除my.cnf 中 skip-federated 这一行]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>源码</tag>
        <tag>centos</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos修改selinux]]></title>
    <url>%2F2016%2F11%2F11%2F20161111-centos%E4%BF%AE%E6%94%B9selinux%2F</url>
    <content type="text"><![CDATA[http://www.centoscn.com/CentOS/config/2015/0618/5681.html]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>selinux</tag>
        <tag>cenots</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos使用外部smtp发送邮件]]></title>
    <url>%2F2016%2F11%2F10%2F20161110-centos%E4%BD%BF%E7%94%A8%E5%A4%96%E9%83%A8smtp%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[在一些小的调度里面，用shell+crontab。这样比较简单和方便，但是没有通知机制。那就用mail来顶上。 ¶1. 安装mail 1yum install mailx -y # -y 默认yes ¶2. 配置外部smtp发送邮件 1234567vi /etc/mail.rc## 新增以下set from=xxxxx@qq.comset smtp=smtp.qq.comset smtp-auth-user=xxxxx@qq.comset smtp-auth-password=XXXXXXXXset smtp-auth=login ¶3. 发送邮件 ¶3.1 使用管道进行邮件发送 1echo &quot;hello&quot; | mail -s &quot;test&quot; XXXXX@qq.com ¶3.2 使用文件进行邮件发送 1mail -s &quot;test&quot; XXXXX@qq.com &lt;/opt/a.txt ¶3.3 发送附件 1mail -s &quot;test&quot; -a /opt/b.txt XXXXX@qq.com &lt;/opt/a.txt]]></content>
      <categories>
        <category>centos</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>mail</tag>
        <tag>smtp</tag>
        <tag>邮件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git for windows中文乱码]]></title>
    <url>%2F2016%2F11%2F07%2F20161107-git-for-windows-%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%2F</url>
    <content type="text"><![CDATA[Git 是在linux下开发的，而 Windows的默认编码为GBK，Linux 的编码方式默认是 UTF-8 的，所以移植到 Windows 之后难免会存在编码冲突，导致乱码。 Git 在 Windows 下有多种乱码情况，请按具体情况操作 Git 安装目录为 C:\Git ¶1.使用 git add 命令添加文件名含中文字符的 文件时 ¶1.1 乱码类似： \316\304\261\276\316\304\265\265.txt ¶1.2 解决方案： 编辑 C:\Git\etc\inputrc 文件中对应的行，查找以下2行，并修改其值，原先： set output-meta off set convert-meta on 改为： set output-meta on set convert-meta off ¶2. 使用git log查看含有中文的log信息时 ¶2.1 乱码类似： &lt;E4&gt;&lt;BF&gt;&lt;AE&gt;&lt;E6&gt;&lt;94&gt;&lt;B9&gt;&lt;E6&gt;&lt;96&gt;&lt;87&gt;&lt;E6&gt;&lt;9C&gt;&lt;AC&gt;&lt;E6&gt;&lt;96&gt;&lt;87&gt;&lt;E6&gt;&lt;A1&gt;&lt;A3&gt; ¶2.2 解决方案： 在Bash提示符下输入： git config --global i18n.commitencoding utf-8 git config --global i18n.logoutputencoding gbk 注：设置 commit 提交时使用 utf-8 编码，可避免 Linux 服务器上乱码；同时设置在执行 git log 时将 utf-8 编码转换成 gbk 编码，以解决乱码问题。编辑 C:\Git\etc\profile 文件，添加如下一行： export LESSCHARSET=utf-8 注：以使git log可以正常显示中文（需要配合：i18n.logoutputencoding gbk） ¶3.使用ls命令查看含有中文的文件名乱码时 ¶3.1 乱码类似： ????.txt ???????.md ¶3.2 解决方案： 使用 ls --show-control-chars 命令来强制使用控制台字符编码显示文件名，即可查看中文文件名。为了方便使用，可以编辑 C:Gitetcgit-completion.bash 文件，添加如下一行： alias ls=&quot;ls --show-control-chars&quot; ¶4.在Git Gui中查看UTF-8编码的文本文件时 ¶4.1 乱码类似： 锘夸腑鏂囨枃妗￡ ¶4.2 解决方案： 在Bash提示符下输入： git config --global gui.encoding utf-8 注：通过上述设置，UTF-8 编码的文本文件可以正常查看，但是 GBK 编码的文件将会乱码，所以还是没有从根本上解决问题。 可行的方法之一为：将所有文本文件的编码统一为 UTF-8 或 GBK，然后设置相应的gui.encoding 参数为 utf-8 或 gbk。 转自：https://segmentfault.com/a/1190000000578037]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>中文乱码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git多用户]]></title>
    <url>%2F2016%2F11%2F07%2F20161107-git%E5%A4%9A%E7%94%A8%E6%88%B7%2F</url>
    <content type="text"><![CDATA[¶1. 生成key 终端下执行 : 12&gt; cd ~/.sshssh-keygen -t rsa -C 'xxxxx@github.com' -f id_rsa_github 其中xxxxx@github.com 替换为你的邮箱， id_rsa_github为生成文件文件名，执行后会问你是否需要enter a passphrase， 默认一路确认就行。 ¶2. 添加到 ssh-agent 将新生成的key 添加到 ssh-agent 12ssh-agent bash or ssh-agent zshssh-add ~/.ssh/id_rsa_github 同时也可以通过命令 ssh-add -l 查看之前已添加的key。 ¶3. 添加公匙到账户 1clip &lt; ~/.ssh/id_rsa_github.pub 重复执行以上步骤,配置你的其他账户 1ssh-keygen -t rsa -C &apos;xxxxx@qq.com&apos; -f id_rsa_qq ¶4. 配置 123456789101112&gt; cd ~/.ssh/ &gt; vi configHost github.com HostName github.com IdentityFile ~/.ssh/id_rsa_github User name1 Email xxxx@163.comHost git.coding.net HostName git.coding.net IdentityFile ~/.ssh/id_rsa_qq User name2 Email xxxx@163.com ¶5. 测试 12ssh -vT git@github.comssh -vT git@git.coding.net ¶6. 有可能碰到的问题 ¶1、Could not open a connection to your authentication agent？应该是 ssh-agent 没有启动，执行以下命令启动 12eval `ssh-agent -s`ssh-add ¶2、Permission denied， 这个问题，注意一下配置文件里面的Host和HostName 转自：https://segmentfault.com/a/1190000007116113]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>git多用户</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CDH安装hadoop集群（目前更新到一半，待续）]]></title>
    <url>%2F2016%2F11%2F07%2F20161107-CDH%E5%AE%89%E8%A3%85hadoop%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[¶1. 虚拟机设置（这里使用的是nat模式） ¶1.1 子网IP段和子网掩码 vm&gt;&gt;编辑&gt;&gt;虚拟网络编辑器&gt;&gt;VMnet8&gt;&gt;勾选连接到此网络&gt;&gt;子网Ip和子网掩码设置 ¶1.2 网关设置 vm&gt;&gt;编辑&gt;&gt;虚拟网络编辑器&gt;&gt;VMnet8&gt;&gt;NAT设置 ¶1.3 如果子网连不上宿主机或者宿主机ping通虚拟机 网络共享中心&gt;&gt;更改适配器设置&gt;&gt;VMnet8&gt;&gt;属性&gt;&gt;TCP/IPv4&gt;&gt;使用静态 ¶2.虚拟机安装 ¶2.1 虚拟机下载地址： http://www.centoscn.com/plus/download.php?open=2&amp;id=2196&amp;uhash=a6241d87fed784a11883750b ¶2.2 安装（略） ¶3. 虚拟机基本配置（root用户） ¶3.1 ip设置 vi /etc/sysconfig/network-scripts/ifcfg-eth0 12345678DEVICE=eth0BOOTPROTO=staticHWADDR=00:0C:29:89:7A:DCONBOOT=yesIPADDR=192.168.136.111NETMASK=255.255.255.0GATEWAY=192.168.136.2DNS1=192.168.136.2 ¶3.2 修改主机名字 vi /etc/sysconfig/network 123NETWORKING=yesNETWORKING_IPV6=noHOSTNAME=cdh.master ¶3.3 创建hadoop用户 12groupadd hadoop #添加一个叫hadoop的用户组useradd hadoop -g hadoop #添加一个hadoop用户并加入hadoop组 ¶3.4 赋予sudo权限 vi /etc/sudoers 1hadoop ALL=(ALL) ALL #在sudoers尾部加上这一行 修改hostname: vi /etc/sysconfig/network 修改hosts #设置hosts文件，这样计算机之间就可以用计算机名来访问了 vi /etc/hsots service network restart 配置ssh免密码登录 ssh-keygen -t rsa -P “” scp id_rsa.pub cdh.scm:/root/.ssh/id_rsa.pub.master scp id_rsa.pub cdh.scm:/root/.ssh/id_rsa.pub.slave01 scp id_rsa.pub cdh.scm:/root/.ssh/id_rsa.pub.slave02 scp id_rsa.pub cdh.scm:/root/.ssh/id_rsa.pub.slave03 cat id_rsa.pub &gt;&gt; authorized_keys cat id_rsa.pub.master &gt;&gt; authorized_keys cat id_rsa.pub.slave01 &gt;&gt; authorized_keys cat id_rsa.pub.slave02 &gt;&gt; authorized_keys cat id_rsa.pub.slave03 &gt;&gt; authorized_keys scp authorized_keys cdh.master:/root/.ssh/ scp authorized_keys cdh.slave01:/root/.ssh/ scp authorized_keys cdh.slave02:/root/.ssh/ scp authorized_keys cdh.slave03:/root/.ssh/ chmod 700 ~/.ssh chmod 644 ~/.ssh/authorized_keys ¶4. 配置JDK 建议用root用户安装，使用时配置环境变量 ¶4.1 下载JDK（建议使用oraclejdk,不建议使用openjdk） http://www.oracle.com/technetwork/java/javase/index.html ¶4.2 上传（略） ¶4.3 解压安装 这里上传到/opt目录下的 12tar -xzvf /opt/jdk-7u80-linux-x64.tar.gz #解压mv /opt/jdk1.7.0_80 /usr/local/jdk1.70_80 #移动到/usr/lcoal ¶4.4 给hadoop用户配置java环境 vi ~/.bashrc 新增以下 12export JAVA_HOME=/usr/local/jdk1.70_80export PATH=$PATH:$JAVA_HOME/bin ¶切换回hadoop测试 echo $JAVA_HOME 输出 ¶5. 克隆虚拟机 ¶5.1 克隆2台 ¶5.2 修改ip和网卡地址 Bringing up interface eth0: Error: No suitable device found: no device found for connection ‘System eth0’. service network restart ¶5.3 测试 http://archive.cloudera.com/cm5/redhat/6/x86_64/cm/cloudera-manager.repo http://archive.cloudera.com/cm5/installer/5.4.5/cloudera-manager-installer.bin http://101.96.10.60/archive.cloudera.com/cm5/redhat/6/x86_64/cm/5.4.5/RPMS/ rpm 安装顺序 enterprise-debuginfo-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-daemons-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-server-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-server-db-2-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-agent-5.4.5-1.cm545.p0.5.el6.x86_64.rpm 所依赖的服务： yum -y install postgresql-server postgresql httpd perl bind-utils libxslt cyrus-sasl-gssapi redhat-lsb cyrus-sasl-plain portmap fuse fuse-libs nc python-setuptools yum -y install httpd perl bind-utils libxslt cyrus-sasl-gssapi redhat-lsb cyrus-sasl-plain portmap fuse fuse-libs nc python-setuptools 安装报错： SELinux is enabled. It must be disabled to install and use this product. 是由于没有关闭：SELinux setenforce 0 临时关闭 修改 /etc/selinux/config 下的 SELINUX=disabled （重启后永久生效） cp cloudera-manager.repo /etc/yum.repos.d yum list|grep cloudera #如果列出的不是你安装的版本，执行下面命令重试 yum clean all yum list | grep cloudera yum -y install *.rpm cp CDH-5.4.2-1.cdh5.4.2.p0.2-el6.parcel CDH-5.4.2-1.cdh5.4.2.p0.2-el6.parcel.sha manifest.json /opt/cloudera/parcel-repo scp -r /opt/cdh cdh.slave01:/opt/ scp -r /opt/cdh cdh.slave02:/opt/ scp -r /opt/cdh cdh.slave03:/opt/ yum -y install ntp chkconfig ntp no ntpdate -u ntp.sjtu.edu.cn — 一定要记住关闭防火墙 不然在yum的时候会报错 couldn’t connect to host 或者一些另外的错误 恢复未完成的安装 rm -Rf /usr/share/cmf /var/lib/cloudera* /var/cache/yum/cloudera* 有的时候可能出现网路问题导致不能连接 错误： Package does not match intended download. Suggestion: run yum --enablerepo=cloudera-manager clean metadata http://blog.csdn.net/huangyanlong/article/details/44050117 设置hosts 记着重启服务。 如果还是报错 yum clean all Error: Cannot find a valid baseurl for repo: base 新增rpm mkdir -p cm5/redhat/6/x86_64/cm/5/RPMS/x86_64/ 将rpm拷贝到该路径 新增xml mkdir cm5/redhat/6/x86_64/cm/5/repodata/ 安装mysql 然后db 配置mysql 启动scm 然后图形安装 报错 手动安装 yum install --skip-broken cloudera-manager-daemons-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-agent-5.4.5-1.cm545.p0.5.el6.x86_64.rpm 继续安装，然后这个包一直下载不了，自动安装 ：bigtop-tomcat yum install --skip-broken 由于依赖 bigtop-utils 那就又下载然后继续一起安装 yum install -y --skip-broken bigtop-tomcat-0.7.0+cdh5.4.5+0-1.cdh5.4.5.p0.8.el6.noarch.rpm bigtop-utils-0.7.0+cdh5.4.5+0-1.cdh5.4.5.p0.8.el6.noarch.rpm 又来一个 hadoop-kms yum install -y 不行了，这个依赖的包太多了，只能放大招 把 archive.cloudera.com 映射到自己的机器上面。前提是：自己下载有完整的包 1、htdocs\cm5\redhat\6\x86_64 把下载的cdh目录拷贝到 htdocs\cm5\redhat\6\x86_64 目录下 2、设置hosts 172.16.100.23 archive.cloudera.com 172.16.100.23 为自己机器的 Apache2.2服务的机器 ping archive.cloudera.com ip为自己机器就行了 然而不知道为什么它要去找高版本，我的服务器上面只有5.4.5版本 放弃 使用这种方式 换一种 选择存储器的时候选择 parcel 方式 把 parcel拷贝到 /opt/cloudera/parcel-repo/ 目录下 忘记添加主机了 关机 全部重启 service cloudera-scm-server start service cloudera-scm-server restart 启动比较慢，如果是急性子可以看看日志 tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log cdh安装中遇到“正在获取安装锁” 解决办法：进入/tmp 目录，ls -a查看，删除scm_prepare_node.*的文件，以及.scm_prepare_node.lock文件。 数据库连接不上 grant all on cdh.* TO ‘root’@’%’ IDENTIFIED BY ‘123’; FLUSH PRIVILEGES; 返回 在继续 报错：JDBC driver cannot be found. Unable to find the JDBC database jar on host : cdh.slave01. 拷贝jar到该目录 /usr/share/java/mysql-connector-java.jar /var/log/cloudera-scm-installer : 安装日志目录。 /var/log/* : 相关日志文件（相关服务的及CM的）。 /usr/lib64/cmf/ : Agent程序代码。 /var/lib/cloudera-scm-server-db/data : 内嵌数据库目录。 /usr/bin/postgres : 内嵌数据库程序。 /etc/cloudera-scm-agent/ : agent的配置目录。 /etc/cloudera-scm-server/ : server的配置目录。 /etc/clouder-scm-server/db.properties 默认元数据库用户名密码配置 /opt/cloudera/parcels/ : Hadoop相关服务安装目录。 /opt/cloudera/parcel-repo/ : 下载的服务软件包数据，数据格式为parcels。 /opt/cloudera/parcel-cache/ : 下载的服务软件包缓存数据。 /etc/hadoop/* : 客户端配置文件目录。 1、机器选型 小型机–百万级别–成本太高。不适用 pcservice–第一选择（屌丝逆袭） 云主机（阿里云、腾讯云、亚马逊云）–创业公司首选（资金不足，数据逐步增大） pc–（实验环境） 2、软件选型 oraclejdk hadoop: a、apache b、cdh c、hdp os: centos6.5 3、网络设备 机器 12 CDH SCM* master namenode rm1 zk slave01 namenode datanode rm 2 nm ZK slave02 datanode nm ZK slave02 datanode nm ZK ########################################################################################## 1、使用lvm分区，然后安装centos分区 关闭防火墙： service iptables stop chkconfig iptables off 2、安装jdk 3、克隆机器 service iptables stop chkconfig iptables off ifconfig 查看mac地址 vi /etc/sysconfig/network-sicp/ifcfg-eth0 servcice network restart 4、在管理机器上面安装mysql 5、创建数据库 create database cdh DEFAULT CHARACTER SET utf8; grant all on cdh.* TO ‘root’@’%’ IDENTIFIED BY ‘123’; flush privileges; #刷新权限 直接赋予超级权限： grant all privileges on . to hive@&quot;%&quot;identified by “123456”; flush privileges; #刷新权限 5、上传jdbc包 -mkdir -p /usr/share/java/ cp /opt /usr/share/java/mysql-connector-java.jar 6、使用官网中B的方式安装 7、安装cloudera-manager 这一些 安装顺序如下 cloudera-manager-daemons-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-server-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-agent-5.4.5-1.cm545.p0.5.el6.x86_64.rpm enterprise-debuginfo-5.4.5-1.cm545.p0.5.el6.x86_64.rpm #设置托管服务的数据库为mysql sh /usr/share/cmf/schema/scm_prepare_database.sh mysql cdh root 123 不知道为什么设置了，还是要下载psotgrepsql 放大招： rpm -i --force --nodeps rpmname cloudera-manager-server-db-2-5.4.5-1.cm545.p0.5.el6.x86_64.rpm 8、复制托管服务软件包到目录 CDH-5.4.2-1.cdh5.4.2.p0.2-el6.parcel manifest.json CDH-5.4.2-1.cdh5.4.2.p0.2-el6.parcel.sha 将上面3个文件都拷贝到下以下目录 /opt/cloudera/parcel-repo cp /opt/scm/CDH-5.4.2-1.cdh5.4.2.p0.2-el6.parcel /opt/scm/CDH-5.4.2-1.cdh5.4.2.p0.2-el6.parcel.sha /opt/scm/manifest.json /opt/cloudera/parcel-repo/ 安装 cloudera-manager-agent-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-daemons-5.4.5-1.cm545.p0.5.el6.x86_64.rpm yum install -y --skip-broken cloudera-manager-daemons-5.4.5-1.cm545.p0.5.el6.x86_64.rpm cloudera-manager-agent-5.4.5-1.cm545.p0.5.el6.x86_64.rpm 添加hosts 10 修改 /etc/hosts 增加 192.168.136.10 cdh.scm 192.168.136.11 cdh.master 192.168.136.12 cdh.slave1 192.168.136.13 cdh.slave2 192.168.136.14 cdh.slave3 9、启动服务 tail -f /var/log/cloudera-scm-server/cloudera-scm-server.log 10 修改 /etc/hosts 增加 172.16.3.31 kvm 172.16.3.32 cdh.scm 172.16.3.33 cdh.master 172.16.3.34 cdh.slave01 172.16.3.35 cdh.slave02 172.16.3.36 cdh.slave03 192.168.136.11 cdh.master 192.168.136.12 cdh.slave1 192.168.136.13 cdh.slave2 192.168.136.14 cdh.slave3 添加主机 echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag echo never &gt; /sys/kernel/mm/transparent_hugepage/defrag /opt/mysql/bin/mysqld_safe --defaults-file=/opt/mysql/my.cnf 注意： select host,user,password from mysql.user; mysql 通过主机名的密码是多少 内存大小问题 /etc/default/cloudera-scm-server mysql 自动启动脚本有问题。 需要重新写一个 service cloudera-scm-server start service cloudera-scm-server restart Event Server 运行不良 一直找不到原因，后来发现 Selinux 没有关 setenforce 0 临时关闭 修改 /etc/selinux/config 下的 SELINUX=disabled （重启后永久生效） Cloudera 建议将 /proc/sys/vm/swappiness 设置为 0。当前设置为 60。 echo 0 &gt; /proc/sys/vm/swappiness 检查主机正确性时出现 “已启用“透明大页面”，它可能会导致重大的性能问题。” 的警告，进行如下设定 vi /etc/sysctl.conf vm.swappiness = 0 sysctl –p 检查主机正确性时出现 “已启用“透明大页面”，它可能会导致重大的性能问题。” 的警告，进行如下设定 echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled 2016-11-25 15:33:34,586 WARN 358018152@scm-web-10:com.cloudera.server.web.cmf.EventsController: (2 skipped) Exception querying events org.apache.avro.AvroRemoteException: java.net.ConnectException: 拒绝连接 create database cdh DEFAULT CHARACTER SET utf8; create database hive DEFAULT CHARACTER SET utf8; create database oozie DEFAULT CHARACTER SET utf8; grant all on hive.* TO ‘root’@’%’ IDENTIFIED BY ‘123’; grant all on oozie.* TO ‘root’@’%’ IDENTIFIED BY ‘123’; grant all on hue.* to ‘root’@’%’ identified by ‘123’; flush privileges; #刷新权限 grant select,insert,update,delete on %.* to root@“cdh.scm” identified by “123456”; /etc/hadoop/conf.impala/hdfs-site.xml /etc/hadoop/conf.empty/hdfs-site.xml /usr/lib/hadoop-0.20-mapreduce/example-confs/conf.pseudo/hdfs-site.xml /usr/lib/hadoop-0.20-mapreduce/example-confs/conf.secure/hdfs-site.xml /usr/lib/spark-1.6.2/conf/hdfs-site.xml 52:54:00:FE:42:EA sh /usr/share/cmf/schema/scm_prepare_database.sh mysql cdh root 123 sh /usr/share/cmf/schema/scm_prepare_database.sh mysql cdh root 123]]></content>
      <categories>
        <category>hadoop</category>
      </categories>
      <tags>
        <tag>chd</tag>
        <tag>hadoop</tag>
        <tag>vm</tag>
        <tag>hadoop集群安装</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[建站日记]]></title>
    <url>%2F2016%2F11%2F03%2F20161103-%E5%BB%BA%E7%AB%99%E6%97%A5%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[本来想着用一个单独的页面来记录建站的过程，后来想了想还是用文章记录吧。 ¶最初: Typecho 20160409 建立Tyecho的blog 域名：liyang.one ¶目前：Hexo+github/coding 20161102 hexo的搭建与基本配置。 域名暂为：ermao.cf 20161103 更改主题next. 增加评论 背景动画 统计 域名更改为：liyang.one 20161104 文章的迁移 留言页 公益404 sitemap网站地图 非友情链接的出站链接添加&quot;nofollow&quot;标签 添加蜘蛛协议 20161121 代码压缩，压缩了js、css、html、图片。 新增机器的计划任务，每天晚上9点自动同步更新博客。 新增搜索功能 新增百度自动推送 20161122 新增百度主动推送（每天同步博客的时候主动推送给百度） 20170413 域名更改：liyang.one更改为liyang.site ¶计划： 谷歌推送 high一下]]></content>
      <categories>
        <category>建站日记</category>
      </categories>
      <tags>
        <tag>日记</tag>
        <tag>建站日记</tag>
        <tag>建站</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Blog：Typecho迁移到Hexo]]></title>
    <url>%2F2016%2F11%2F02%2F20161102-Blog%EF%BC%9ATypecho%E8%BF%81%E7%A7%BB%E5%88%B0Hexo%2F</url>
    <content type="text"><![CDATA[迁移的第一天，写个文章助助兴 不知不觉已经工作三年了，毕业两年，实习一年。从2016年04月09日搭建博客到现在一共更新了2篇文章。哈哈哈，虽然建了很久但是确实是几乎没怎么维护。 为什么要迁移到Hexo呢？在知乎上面看到了一段话： 第一阶段，刚接触Blog，觉得很新鲜，试着选择一个免费空间来写。 第二阶段，发现免费空间限制太多，就自己购买域名和空间，搭建独立博客。 第三阶段，觉得独立博客的管理太麻烦，最好在保留控制权的前提下，让别人来管，自己只负责写文章。 算是技术的一个积累吧，大脑是CPU不是硬盘，缓存就那么大装不了多少的。 方便查询，有些问题自己解决了，当别人问你的时候方便别人。也方便自己，温故知新。 无聊 差不多就这么多吧，以后多多更新技术文档。]]></content>
      <categories>
        <category>随想</category>
      </categories>
      <tags>
        <tag>随想</tag>
        <tag>迁移</tag>
        <tag>typecho</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给程序员忠告-自勉]]></title>
    <url>%2F2016%2F08%2F17%2F20160817-%E7%BB%99%E7%A8%8B%E5%BA%8F%E5%91%98%E5%BF%A0%E5%91%8A-%E8%87%AA%E5%8B%89%2F</url>
    <content type="text"><![CDATA[¶一、生在屌丝家，逆袭靠自己 从事我们这一行的父母多是农村或者城市底层，他们给我们的爱跟富人给他们孩子的爱没有任何差别。你父母让你今天能四肢健全、健健康康、大脑灵光的来到大城市打工挣钱。你父母给了你今生最大的本钱，如果自己活得像个废柴，别怨出身，检讨自己是大脑不好使还是身体懒惰。&gt;从事我们这一行的父母多是农村或者城市底层，他们给我们的爱跟富人给他们孩子的爱没有任何差别。你父母让你今天能四肢健全、健健康康、大脑灵光的来到大城市打工挣钱。你父母给了你今生最大的本钱，如果自己活得像个废柴，别怨出身，检讨自己是大脑不好使还是身体懒惰。 如果你不是富二代，就要想办法成为富二代他爹。 ¶二、看到这个行业的闪光面 很少有哪个行业像IT业一样有那么多就业机会，每年批量的制造白领。能给二十多岁就会写几段代码其他能力都是白纸的进城务工人员开那么高的工资。自己拍着良心想想，如果自己换到机器、化工及其他工科专业，甚至文科专业，有多少就业机会，对刚工作几年的开多高的工资？能不能给你那么多的跳槽机会让你频繁更换老板去追逐更高的收入。 ¶三、多行动少抱怨 每天进步千分之一，一年后你就是现在1.44倍，十年以后你的水平是现在的38.4倍。刚出道强你几倍的人都会被你像蚂蚁一样踩在脚下。只要你能做严格要求自己，你总会成为让老板器重对手害怕的人。 每天退步千分之一，一年后你就剩下现在的69.4%，十年后你就剩下现在的2.59%，无论是出道时候有多了不起的人，混日子都能将他混成废柴中的极品。 老板们愿意为岁月历练出来的精英开高价，却不会施舍半口饭给高龄的战五渣。 ¶四、明白自己不是世界中心 这个世界运行的法则，一靠资本、二靠创新，最后才是靠技术。有钱的才是爷，你就是个伺候爷换钱养家的人。有本事自己做老板，没本事就别摆知识分子的臭架子，老老实实做好的孙子。实在不爽就换老板，但千万不要让自己现在伺候的老板不爽。 ¶五、站在更高的角度思考问题 这个世界每个人的境界是不一样的，佛的境界最高在天上，老板的境界比你高在山顶上，你的境界在地上仅仅比程序代码高那么一点点。 不要抱怨老板为什么老改需求，而是要用心去想老板为什么要改需求。老板是站在山顶上看大局的人，你是山下那个种地的只见自己的一亩三分地。只有傻逼才会要求老板跑到山下按自己的处境去思考问题。能把自己的眼界拔高一点点，你就和老板接近一点，也就离摆脱屌丝身份更近了一点。 ¶六、找个勤劳节俭的女人成立家庭很重要 老婆不是拿来看的，别按着网页美女或者游戏美女标准去找老婆。要相信人的福祸是相依的，屌丝能娶到美女是福气，但必定会付出其他代价偿还，会接连的发生人生损失。 勤劳节俭的女人是旺夫相，能助你尽快脱屌，也能在你日后陷入事业低潮期时候助你脱困。 ¶七、广交朋友 只有一辈子不想发财的人才不用交朋友。 朋友交谈中无心中的话语都可能蕴藏商机，遇事有朋友就好办的多，以后想创业，更离不开朋友圈子。 ¶八、积极理财蓄势待发 绝对不要只把眼睛放在代码上，会写代码能给你一份固定收入，但这份收入顶多能让你一家温饱小康，捉襟见肘的日子将伴你终生。 放下愤青的偏激成见，承认天地有缺陷、人间无极乐的客观现实，从客观现状去了解时代，学习经济，规避损失，把握投资机会，先建好自己的小家，再去管天下大家的事。 家底夯厚了，机会来了可以拉起几个朋友做点事，机会不到也能保一家人比较殷实的过一生。 转自：http://blog.csdn.net/an342647823/article/details/40318361#comments]]></content>
      <categories>
        <category>励志</category>
      </categories>
      <tags>
        <tag>转发</tag>
        <tag>励志</tag>
        <tag>程序员</tag>
        <tag>程序猿</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pentaho Kettle解决方案：使用PDI构建开源ETL解决方案]]></title>
    <url>%2F2016%2F04%2F20%2F20160420-Pentaho-Kettle%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%EF%BC%9A%E4%BD%BF%E7%94%A8PDI%E6%9E%84%E5%BB%BA%E5%BC%80%E6%BA%90ETL%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[¶内容简介 本书主要介绍如何使用开源ETL工具来完成数据整合工作。 本书介绍的PDI(Kettle)是一种开源的 ETL 解决方案，书中介绍了如何使用PDI来实现数据的剖析、清洗、校验、抽取、转换、加载等各类常见的ETL类工作。 除了ODS/DW类比较大型的应用外，Kettle 实际还可以为中小企业提供灵活的数据抽取和数据处理的功能。Kettle除了支持各种关系型数据库、HBase、MongoDB这样的NoSQL数据源外，它还支持Excel、Access这类小型的数据源。并且通过插件扩展，Kettle可以支持各类数据源。本书详细介绍了Kettle可以处理的数据源，而且详细介绍了如何使用Kettle抽取增量数据。 Kettle 的数据处理功能也很强大，除了选择、过滤、分组、连接、排序这些常用的功能外，Kettle 里的Java表达式、正则表达式、Java脚本、Java类等功能都非常灵活而强大，都非常适合于各种数据处理功能。本书也使用了一些篇幅介绍Kettle这些灵活的数据处理功能。本书后面章节介绍了如何在Kettle上开发插件，如何使用Kettle处理实时数据流，以及如何在 AWS上运行Kettle 等一些高级主题。 除了介绍PDI(Kettle)工具的使用和功能，本书还结合Kimball博士的数据仓库和ETL子系统的理论，从实践的角度介绍数据仓库的模型设计、数据仓库的构建方法，以及如何使用 PDI实现Kimball博士提出的34种ETL子系统。 ¶作者介绍 初建军 北京傲飞科技有限公司CEO，炼数成金社区BI方向授课专家，常年从事商业智能、数据挖掘、数据分析等工作，致力于推广开源BI软件。 ¶预览与下载 点击在线预览 点击下载]]></content>
      <categories>
        <category>etl</category>
      </categories>
      <tags>
        <tag>kettle</tag>
        <tag>资源</tag>
        <tag>etl</tag>
        <tag>使用PDI构建开源ETL解决方案</tag>
      </tags>
  </entry>
</search>